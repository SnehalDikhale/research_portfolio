import { ResearchPillar, Publication, ImpactMetric } from "./types";

export const researchPillars: ResearchPillar[] = [
  {
    id: "multimodal-foundation-models",
    title: "Multimodal Foundation Models & Reasoning",
    subtitle: "Action-Conditioned World Models",
    description:
      "Architecting next-generation Vision-Language Models with custom projection layers to enable physical reasoning and action conditioning for robotic manipulation tasks.",
    icon: "ðŸ§ ",
    color: "purple",
    projects: [
      {
        id: "vlm-reasoning-latency",
        title: "Low-Latency VLM Architecture",
        description:
          "Developed custom projection layers and architectural modifications to VLM backbones, achieving real-time inference for robotic control applications.",
        impact: "7x latency reduction",
        technologies: ["PyTorch", "Transformers", "HuggingFace", "CUDA"],
        url: "#",
      },
      {
        id: "action-conditioned-models",
        title: "Action-Conditioned World Models",
        description:
          "Implemented action-conditioned architectures that improve task success rates by incorporating physical reasoning into the model's decision-making process.",
        impact: "25% task success improvement",
        technologies: ["LLMs", "PyTorch", "Reinforcement Learning"],
        url: "#",
      },
      {
        id: "failure-reasoning",
        title: "VLM-based Failure Reasoning",
        description:
          "Developed vision-language models for autonomous failure detection and reasoning in robotic systems, enabling self-correction and adaptive behavior.",
        impact: "Patent filed 2025",
        technologies: ["GPT-4V", "CLIP", "Computer Vision"],
        url: "#",
      },
    ],
  },
  {
    id: "tactile-perception",
    title: "Physics-Informed Tactile Perception",
    subtitle: "Closing the Sim-to-Real Gap",
    description:
      "Pioneering hardware-agnostic representations for vision-tactile fusion through physics-informed simulation and domain randomization techniques.",
    icon: "ðŸ¤–",
    color: "blue",
    projects: [
      {
        id: "sim-to-real-gap",
        title: "Sim-to-Real Transfer Framework",
        description:
          "Built domain-randomized dataset of 220k samples in Unreal Engine with physics-based tactile simulation, achieving unprecedented sim-to-real transfer performance.",
        impact: "65% sim-to-real gap reduction",
        technologies: ["Unreal Engine", "Domain Randomization", "Physics Simulation"],
        url: "#",
      },
      {
        id: "hypertaxel",
        title: "HyperTaxel Resolution Enhancement",
        description:
          "Developed hyper-resolution techniques for taxel-based tactile signals, dramatically improving spatial resolution of tactile sensors without hardware changes.",
        impact: "3x resolution improvement",
        technologies: ["Deep Learning", "Signal Processing", "Computer Vision"],
        url: "#",
      },
      {
        id: "graph-neural-networks",
        title: "Hierarchical Graph Neural Networks",
        description:
          "Designed dynamic spatio-temporal graph architectures for proprioceptive and tactile sensor fusion, enabling accurate 6D pose estimation.",
        impact: "State-of-the-art 6D pose",
        technologies: ["GNNs", "PyTorch Geometric", "ROS", "C++"],
        url: "#",
      },
    ],
  },
];

export const impactMetrics: ImpactMetric[] = [
  {
    id: "latency-reduction",
    label: "Reasoning Latency Reduction",
    value: "7x",
    description: "Achieved through custom VLM architecture optimization for real-time robotic control",
    icon: "âš¡",
    trend: "up",
    size: "large",
  },
  {
    id: "sim-to-real",
    label: "Sim-to-Real Gap Reduction",
    value: "65%",
    description: "Physics-informed domain randomization in Unreal Engine with 220k training samples",
    icon: "ðŸ”„",
    trend: "up",
    size: "large",
  },
  {
    id: "task-success",
    label: "Task Success Improvement",
    value: "25%",
    description: "Action-conditioned world models for physical reasoning",
    icon: "ðŸŽ¯",
    trend: "up",
    size: "medium",
  },
  {
    id: "tactile-resolution",
    label: "Tactile Resolution",
    value: "3x",
    description: "HyperTaxel hyper-resolution for taxel-based tactile signals",
    icon: "ðŸ“Š",
    trend: "up",
    size: "medium",
  },
  {
    id: "dataset-size",
    label: "Domain-Randomized Dataset",
    value: "220k",
    description: "Samples generated in Unreal Engine for sim-to-real transfer",
    icon: "ðŸ’¾",
    trend: "neutral",
  },
  {
    id: "patents-filed",
    label: "Patents Filed",
    value: "2",
    description: "VLM-based failure reasoning and multimodal action planning (2025)",
    icon: "ðŸ’¡",
    trend: "up",
  },
];

export const publications: Publication[] = [
  {
    id: "pub-dynastgnn",
    title: "DynastGNN: Dynamic Spatio-Temporal Hierarchical Graph Neural Network for Proprioceptive and Tactile Sensing",
    authors: ["S. S. Dikhale", "et al."],
    venue: "IEEE Robotics and Automation Letters (RA-L)",
    year: 2024,
    type: "journal",
    url: "#",
    tags: ["Graph Neural Networks", "Tactile Sensing", "Proprioception", "Sensor Fusion"],
    bibtex: `@article{dikhale2024dynastgnn,
  title={DynastGNN: Dynamic Spatio-Temporal Hierarchical Graph Neural Network for Proprioceptive and Tactile Sensing},
  author={Dikhale, Snehal S. and others},
  journal={IEEE Robotics and Automation Letters},
  year={2024},
  note={Submitted}
}`,
  },
  {
    id: "pub-hypertaxel",
    title: "HyperTaxel: Hyper-Resolution for Taxel-Based Tactile Signals Through Learned Image-to-Image Translation",
    authors: ["S. S. Dikhale", "et al."],
    venue: "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
    year: 2024,
    type: "conference",
    url: "#",
    pdf: "#",
    tags: ["Tactile Sensing", "Deep Learning", "Image-to-Image Translation", "Super-Resolution"],
    bibtex: `@inproceedings{dikhale2024hypertaxel,
  title={HyperTaxel: Hyper-Resolution for Taxel-Based Tactile Signals Through Learned Image-to-Image Translation},
  author={Dikhale, Snehal S. and others},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2024}
}`,
  },
  {
    id: "pub-hgnn-pose",
    title: "Hierarchical Graph Neural Networks for Proprioceptive 6D Pose Estimation of In-Hand Objects",
    authors: ["S. S. Dikhale", "et al."],
    venue: "IEEE International Conference on Robotics and Automation (ICRA)",
    year: 2023,
    type: "conference",
    url: "#",
    pdf: "#",
    code: "#",
    tags: ["Graph Neural Networks", "6D Pose Estimation", "Proprioception", "In-Hand Manipulation"],
    bibtex: `@inproceedings{dikhale2023hgnn,
  title={Hierarchical Graph Neural Networks for Proprioceptive 6D Pose Estimation of In-Hand Objects},
  author={Dikhale, Snehal S. and others},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023}
}`,
  },
  {
    id: "pub-visuotactile",
    title: "Visuotactile 6D Pose Estimation of an In-Hand Object Using Vision and Tactile Sensor Data",
    authors: ["S. S. Dikhale", "et al."],
    venue: "IEEE Robotics and Automation Letters (RA-L) presented at ICRA",
    year: 2022,
    type: "journal",
    url: "#",
    pdf: "#",
    tags: ["Visuotactile", "6D Pose Estimation", "Sensor Fusion", "Manipulation"],
    bibtex: `@article{dikhale2022visuotactile,
  title={Visuotactile 6D Pose Estimation of an In-Hand Object Using Vision and Tactile Sensor Data},
  author={Dikhale, Snehal S. and others},
  journal={IEEE Robotics and Automation Letters},
  year={2022},
  note={Presented at ICRA 2022}
}`,
  },
  {
    id: "patent-vlm-failure",
    title: "Vision-Language Models for Failure Reasoning in Robotic Systems",
    authors: ["S. S. Dikhale"],
    venue: "US Patent Application",
    year: 2025,
    type: "patent",
    tags: ["VLMs", "Failure Detection", "Autonomous Systems"],
  },
  {
    id: "patent-multimodal-planning",
    title: "Context-Aware Multimodal Action Planning for Robotic Manipulation",
    authors: ["S. S. Dikhale"],
    venue: "US Patent Application",
    year: 2025,
    type: "patent",
    tags: ["Multimodal Learning", "Action Planning", "Robotics"],
  },
];
